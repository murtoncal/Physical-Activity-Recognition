{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One File With All the Dissertation Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import medfilt, butter, filtfilt\n",
    "from sklearn import preprocessing\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the respective datasets\n",
    "# USC-HAD\n",
    "def import_USC_HAD_data(activity, subject, trial):\n",
    "    path = f'Data/USC-HAD/Subject{subject}/a{activity}t{trial}.mat'\n",
    "    if Path(path).is_file():\n",
    "        data = loadmat(path)\n",
    "        return data\n",
    "    else:\n",
    "        return None\n",
    "# UTD-MHAD\n",
    "def import_UTD_MHAD_data(activity, subject, trial, data_type):\n",
    "    path = f'Data/UTD MHAD/Inertial/a{activity}_s{subject}_t{trial}_{data_type}.mat'\n",
    "    if Path(path).is_file():\n",
    "        data = loadmat(path)\n",
    "        return data\n",
    "    else:\n",
    "        return None\n",
    "# UCI-HAR (HAPT)\n",
    "def import_UCI_HAR_data(subject, trial, data_type):\n",
    "    path = f'Data/UCI-HAR/RawData/{data_type}_exp{trial}_user{subject}.txt'\n",
    "    if Path(path).is_file():\n",
    "        data = np.loadtxt(path)\n",
    "        data = np.array(data)\n",
    "        return data\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to transform the wearable sensor data of the respective datasets\n",
    "# USC-HAD\n",
    "def transform_inertial_USC_HAD_data(activity, subject, trial):\n",
    "    data = import_USC_HAD_data(activity, subject, trial)\n",
    "    if data is None:return None\n",
    "    inertial_data = data['sensor_readings']\n",
    "    result = np.insert(inertial_data, 0, [[activity], [subject], [trial]], axis=1)\n",
    "    result = np.array(result)\n",
    "    return result\n",
    "#UTD-MHAD\n",
    "def transform_inertial_UTD_MHAD_data(activity, subject, trial):\n",
    "    data = import_UTD_MHAD_data(activity, subject, trial, data_type='inertial')\n",
    "    if data is None:return None\n",
    "    inertial_data = data['d_iner']\n",
    "    result = np.insert(inertial_data, 0, [[activity], [subject], [trial]], axis=1)\n",
    "    result = np.array(result)\n",
    "    return result\n",
    "\n",
    "# functions to convert the tranformed wearable sensor data into a DataFrame\n",
    "# USC-HAD\n",
    "def inertial_USC_HAD_data_df(activity, subject, trial):\n",
    "    data = transform_inertial_USC_HAD_data(activity, subject, trial)\n",
    "    if data is None:return None\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = ['activity', 'subject', 'trial', 'x-acc', 'y-acc', 'z-acc', 'x-gyro', 'y-gyro', 'z-gyro']\n",
    "    return df\n",
    "# UTD-HAD\n",
    "def inertial_UTD_MHAD_data_df(activity, subject, trial):\n",
    "    data = transform_inertial_UTD_MHAD_data(activity, subject, trial)\n",
    "    if data is None:return None\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = ['activity', 'subject', 'trial', 'x-acc', 'y-acc', 'z-acc', 'x-gyro', 'y-gyro', 'z-gyro']\n",
    "    return df\n",
    "# HAPT (UCI-HAR)\n",
    "def inertial_UCI_HAR_data_df(subject, trial):\n",
    "    data_acc = import_UCI_HAR_data(subject, trial, data_type='acc')\n",
    "    data_gyro = import_UCI_HAR_data(subject, trial, data_type='gyro')\n",
    "    if data_acc is None:return None\n",
    "    data_acc_st = np.insert(data_acc, 0, [[subject], [trial]], axis=1)\n",
    "    df1 = pd.DataFrame(data_acc_st)\n",
    "    df2 = pd.DataFrame(data_gyro)\n",
    "    df = pd.concat([df1, df2], axis=1)\n",
    "    df.columns = ['subject', 'trial', 'x-acc', 'y-acc', 'z-acc', 'x-gyro', 'y-gyro', 'z-gyro']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise reduction\n",
    "\n",
    "# the units for the accelerometer readings are m/s-2\n",
    "# the units for the gyroscope readings are s-1\n",
    "def sensor_image(raw_data, frequency):\n",
    "    # calulating the time length of the plot\n",
    "    time = [1/(frequency) * t for t in range(len(raw_data))]\n",
    "    # creating the plot\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    plt.plot(time,raw_data)\n",
    "    plt.xlabel('Time (seconds)', fontsize=18)\n",
    "    plt.ylabel('Sensor Reading', fontsize=18)\n",
    "    plt.ylim([0,6])\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.grid(color='grey', linestyle='--', linewidth=0.2)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sensor_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff= 20  # the cutoff frequency of the filter\n",
    "def butterworth_filter(raw_data,frequency):\n",
    "    W = cutoff/(frequency/2)\n",
    "    # Preparing the low-pass filter\n",
    "    # third order filter\n",
    "    b, a = butter(3, W, 'low')\n",
    "    # Using a filter on the raw data\n",
    "    output = filtfilt(b, a, raw_data)\n",
    "    # Reutrning filtered raw data\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build big dataframes representing the datasets\n",
    "# whilst applying the noise filtering\n",
    "\n",
    "USC_HAD_df = None\n",
    "for activity in range(1,13):\n",
    "    for subject in range(1,15):\n",
    "        for trial in range(1,6):\n",
    "            data = inertial_USC_HAD_data_df(activity, subject, trial)\n",
    "            data_filt = pd.DataFrame()\n",
    "            for label in data.columns[3:9]:\n",
    "                data_filt[label] = butterworth_filter(data[label],100)\n",
    "            data_filt = pd.concat([data['activity'], data['subject'], data['trial'], data_filt], axis=1)\n",
    "            USC_HAD_df = pd.concat([USC_HAD_df, data_filt])\n",
    "\n",
    "UTD_MHAD_df = None\n",
    "for activity in range(1,22):\n",
    "    for subject in range(1,9):\n",
    "        for trial in range(1,5):\n",
    "            data = inertial_UTD_MHAD_data_df(activity, subject, trial)\n",
    "            if data is None: continue # has three missing observations\n",
    "            data_filt = pd.DataFrame()\n",
    "            for label in data.columns[3:9]:\n",
    "                data_filt[label] = butterworth_filter(data[label],50)\n",
    "            data_filt = pd.concat([data['activity'], data['subject'], data['trial'], data_filt], axis=1)\n",
    "            UTD_MHAD_df = pd.concat([UTD_MHAD_df, data_filt])\n",
    "            \n",
    "UCI_HAR_df = None\n",
    "for subject in range(1,31):\n",
    "    for trial in range(1,62):\n",
    "        data = inertial_UCI_HAR_data_df(subject, trial)\n",
    "        if data is None: continue # files are named such that this is required\n",
    "        data_filt = pd.DataFrame()\n",
    "        for label in data.columns[2:8]:\n",
    "            data_filt[label] = butterworth_filter(data[label],50)\n",
    "        data_filt = pd.concat([data['subject'], data['trial'], data_filt], axis=1)\n",
    "        UCI_HAR_df = pd.concat([UCI_HAR_df, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# normalisation\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# USC-HAD\n",
    "USC_act = USC_HAD_df['activity']\n",
    "USC_sub = USC_HAD_df['subject']\n",
    "USC_tr = USC_HAD_df['trial']\n",
    "USC_x_a = USC_HAD_df['x-acc']\n",
    "USC_y_a = USC_HAD_df['y-acc']\n",
    "USC_z_a = USC_HAD_df['z-acc']\n",
    "USC_x_g = USC_HAD_df['x-gyro']\n",
    "USC_y_g = USC_HAD_df['y-gyro']\n",
    "USC_z_g = USC_HAD_df['z-gyro']\n",
    "\n",
    "USC_act = USC_HAD_df['activity'].values.reshape((len(USC_act),1))\n",
    "USC_sub = USC_HAD_df['subject'].values.reshape((len(USC_sub),1))\n",
    "USC_tr = USC_HAD_df['trial'].values.reshape((len(USC_tr),1))\n",
    "USC_x_a = USC_HAD_df['x-acc'].values.reshape((len(USC_x_a),1))\n",
    "USC_y_a = USC_HAD_df['y-acc'].values.reshape((len(USC_y_a),1))\n",
    "USC_z_a = USC_HAD_df['z-acc'].values.reshape((len(USC_z_a),1))\n",
    "USC_x_g = USC_HAD_df['x-gyro'].values.reshape((len(USC_x_g),1))\n",
    "USC_y_g = USC_HAD_df['y-gyro'].values.reshape((len(USC_y_g),1))\n",
    "USC_z_g = USC_HAD_df['z-gyro'].values.reshape((len(USC_z_g),1))\n",
    "\n",
    "USC_x_a_scaled = min_max_scaler.fit_transform(USC_x_a)\n",
    "USC_y_a_scaled = min_max_scaler.fit_transform(USC_y_a)\n",
    "USC_z_a_scaled = min_max_scaler.fit_transform(USC_z_a)\n",
    "USC_x_g_scaled = min_max_scaler.fit_transform(USC_x_g)\n",
    "USC_y_g_scaled = min_max_scaler.fit_transform(USC_y_g)\n",
    "USC_z_g_scaled = min_max_scaler.fit_transform(USC_z_g)\n",
    "\n",
    "USC_scaled_data = np.concatenate((USC_act,USC_sub,USC_tr,USC_x_a_scaled,USC_y_a_scaled,USC_z_a_scaled,USC_x_g_scaled,USC_y_g_scaled,USC_z_g_scaled), axis=1)\n",
    "USC_HAD_df = pd.DataFrame(USC_scaled_data)\n",
    "USC_HAD_df.columns = ['activity', 'subject', 'trial', 'x-acc', 'y-acc', 'z-acc', 'x-gyro', 'y-gyro', 'z-gyro']\n",
    "\n",
    "# UTD-MHAD\n",
    "UTD_act = UTD_MHAD_df['activity']\n",
    "UTD_sub = UTD_MHAD_df['subject']\n",
    "UTD_tr = UTD_MHAD_df['trial']\n",
    "UTD_x_a = UTD_MHAD_df['x-acc']\n",
    "UTD_y_a = UTD_MHAD_df['y-acc']\n",
    "UTD_z_a = UTD_MHAD_df['z-acc']\n",
    "UTD_x_g = UTD_MHAD_df['x-gyro']\n",
    "UTD_y_g = UTD_MHAD_df['y-gyro']\n",
    "UTD_z_g = UTD_MHAD_df['z-gyro']\n",
    "\n",
    "UTD_act = UTD_MHAD_df['activity'].values.reshape((len(UTD_act),1))\n",
    "UTD_sub = UTD_MHAD_df['subject'].values.reshape((len(UTD_sub),1))\n",
    "UTD_tr = UTD_MHAD_df['trial'].values.reshape((len(UTD_tr),1))\n",
    "UTD_x_a = UTD_MHAD_df['x-acc'].values.reshape((len(UTD_x_a),1))\n",
    "UTD_y_a = UTD_MHAD_df['y-acc'].values.reshape((len(UTD_y_a),1))\n",
    "UTD_z_a = UTD_MHAD_df['z-acc'].values.reshape((len(UTD_z_a),1))\n",
    "UTD_x_g = UTD_MHAD_df['x-gyro'].values.reshape((len(UTD_x_g),1))\n",
    "UTD_y_g = UTD_MHAD_df['y-gyro'].values.reshape((len(UTD_y_g),1))\n",
    "UTD_z_g = UTD_MHAD_df['z-gyro'].values.reshape((len(UTD_z_g),1))\n",
    "\n",
    "UTD_x_a_scaled = min_max_scaler.fit_transform(UTD_x_a)\n",
    "UTD_y_a_scaled = min_max_scaler.fit_transform(UTD_y_a)\n",
    "UTD_z_a_scaled = min_max_scaler.fit_transform(UTD_z_a)\n",
    "UTD_x_g_scaled = min_max_scaler.fit_transform(UTD_x_g)\n",
    "UTD_y_g_scaled = min_max_scaler.fit_transform(UTD_y_g)\n",
    "UTD_z_g_scaled = min_max_scaler.fit_transform(UTD_z_g)\n",
    "\n",
    "UTD_scaled_data = np.concatenate((UTD_act,UTD_sub,UTD_tr,UTD_x_a_scaled,UTD_y_a_scaled,UTD_z_a_scaled,UTD_x_g_scaled,UTD_y_g_scaled,UTD_z_g_scaled), axis=1)\n",
    "UTD_MHAD_df = pd.DataFrame(UTD_scaled_data)\n",
    "UTD_MHAD_df.columns = ['activity', 'subject', 'trial', 'x-acc', 'y-acc', 'z-acc', 'x-gyro', 'y-gyro', 'z-gyro']\n",
    "\n",
    "# UCI-HAR\n",
    "UCI_sub = UCI_HAR_df['subject']\n",
    "UCI_tr = UCI_HAR_df['trial']\n",
    "UCI_x_a = UCI_HAR_df['x-acc']\n",
    "UCI_y_a = UCI_HAR_df['y-acc']\n",
    "UCI_z_a = UCI_HAR_df['z-acc']\n",
    "UCI_x_g = UCI_HAR_df['x-gyro']\n",
    "UCI_y_g = UCI_HAR_df['y-gyro']\n",
    "UCI_z_g = UCI_HAR_df['z-gyro']\n",
    "\n",
    "UCI_sub = UCI_HAR_df['subject'].values.reshape((len(UCI_sub),1))\n",
    "UCI_tr = UCI_HAR_df['trial'].values.reshape((len(UCI_tr),1))\n",
    "UCI_x_a = UCI_HAR_df['x-acc'].values.reshape((len(UCI_x_a),1))\n",
    "UCI_y_a = UCI_HAR_df['y-acc'].values.reshape((len(UCI_y_a),1))\n",
    "UCI_z_a = UCI_HAR_df['z-acc'].values.reshape((len(UCI_z_a),1))\n",
    "UCI_x_g = UCI_HAR_df['x-gyro'].values.reshape((len(UCI_x_g),1))\n",
    "UCI_y_g = UCI_HAR_df['y-gyro'].values.reshape((len(UCI_y_g),1))\n",
    "UCI_z_g = UCI_HAR_df['z-gyro'].values.reshape((len(UCI_z_g),1))\n",
    "\n",
    "UCI_x_a_scaled = min_max_scaler.fit_transform(UCI_x_a)\n",
    "UCI_y_a_scaled = min_max_scaler.fit_transform(UCI_y_a)\n",
    "UCI_z_a_scaled = min_max_scaler.fit_transform(UCI_z_a)\n",
    "UCI_x_g_scaled = min_max_scaler.fit_transform(UCI_x_g)\n",
    "UCI_y_g_scaled = min_max_scaler.fit_transform(UCI_y_g)\n",
    "UCI_z_g_scaled = min_max_scaler.fit_transform(UCI_z_g)\n",
    "\n",
    "UCI_scaled_data = np.concatenate((UCI_sub,UCI_tr,UCI_x_a_scaled,UCI_y_a_scaled,UCI_z_a_scaled,UCI_x_g_scaled,UCI_y_g_scaled,UCI_z_g_scaled), axis=1)\n",
    "UCI_HAR_df = pd.DataFrame(UCI_scaled_data)\n",
    "UCI_HAR_df.columns = ['subject', 'trial', 'x-acc', 'y-acc', 'z-acc', 'x-gyro', 'y-gyro', 'z-gyro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-55a49376c19d>:25: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  act_start = np.int(labels_df.iloc[activity,3])\n",
      "<ipython-input-8-55a49376c19d>:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  act_end = np.int(labels_df.iloc[activity,4])\n",
      "<ipython-input-8-55a49376c19d>:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  UCI_HAR_df_act = pd.concat([UCI_HAR_df_act, UCI_HAR_df.iloc[np.int(labels_df.iloc[len(labels_df)-1,3])+act_start_point:np.int(labels_df.iloc[len(labels_df)-1,4])+act_start_point+1,:]])\n",
      "<ipython-input-8-55a49376c19d>:37: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  act['activity'] = [labels_df.iloc[len(labels_df)-1,2]] * (((np.int(labels_df.iloc[len(labels_df)-1,4]))-(np.int(labels_df.iloc[len(labels_df)-1,3])))+1)\n"
     ]
    }
   ],
   "source": [
    "# the UCI_HAR dataset required further preprocessing to correctly label the sensor signals and remove any unlabelled data\n",
    "\n",
    "# import the UCI activity labels\n",
    "path = f'Data/UCI-HAR/RawData/labels.txt'\n",
    "labels = np.loadtxt(path)\n",
    "labels_df = pd.DataFrame(labels)\n",
    "\n",
    "# calculates the during of each activity\n",
    "act_range = []\n",
    "for subject in range(1,31):\n",
    "    for trial in range(1,62):\n",
    "        sub = UCI_HAR_df[UCI_HAR_df['subject'] == subject]\n",
    "        sub_tr = sub[sub['trial'] == trial]\n",
    "        if sub_tr.empty is not True:\n",
    "            act_range.append(len(sub_tr))\n",
    "            \n",
    "# the following code removes the unlabelled data and appropriately labels the remaining data\n",
    "UCI_HAR_df_act = None\n",
    "act_labels= {'activity': []}\n",
    "act_labels_df = pd.DataFrame(data=act_labels)\n",
    "act_start_point = 0\n",
    "trial_count = 0\n",
    "for activity in range(0,len(labels_df)-1):\n",
    "    act = pd.DataFrame()\n",
    "    act_start = np.int(labels_df.iloc[activity,3])\n",
    "    act_end = np.int(labels_df.iloc[activity,4])\n",
    "    act_diff = act_end-act_start+1\n",
    "    UCI_HAR_df_act = pd.concat([UCI_HAR_df_act, UCI_HAR_df.iloc[act_start+act_start_point:act_end+act_start_point+1,:]])\n",
    "    act['activity'] = [labels_df.iloc[activity,2]] * act_diff\n",
    "    act_labels_df = pd.concat([act_labels_df, act], axis=0, ignore_index=False)\n",
    "    if labels_df.iloc[activity+1,3] < labels_df.iloc[activity,3]:\n",
    "        act_start_point = act_start_point + act_range[trial_count]\n",
    "        trial_count = trial_count +1\n",
    "# add the final activity\n",
    "UCI_HAR_df_act = pd.concat([UCI_HAR_df_act, UCI_HAR_df.iloc[np.int(labels_df.iloc[len(labels_df)-1,3])+act_start_point:np.int(labels_df.iloc[len(labels_df)-1,4])+act_start_point+1,:]])\n",
    "act = pd.DataFrame()\n",
    "act['activity'] = [labels_df.iloc[len(labels_df)-1,2]] * (((np.int(labels_df.iloc[len(labels_df)-1,4]))-(np.int(labels_df.iloc[len(labels_df)-1,3])))+1)\n",
    "act_labels_df = pd.concat([act_labels_df, act], axis=0, ignore_index=True)\n",
    "# UCI_HAR_df_proc = pd.concat([act_labels_df,UCI_HAR_df_act], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d9ad6ffa8e62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mUCI_HAR_df_act\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'UCI_HAR_df_act.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mact_labels_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'act_labels_df.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3203\u001b[0m         )\n\u001b[1;32m-> 3204\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    202\u001b[0m             )\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m             d = b.to_native_types(\n\u001b[0m\u001b[0;32m    335\u001b[0m                 \u001b[0mslicer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslicer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m                 \u001b[0mna_rep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mna_rep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mto_native_types\u001b[1;34m(self, slicer, na_rep, float_format, decimal, quoting, **kwargs)\u001b[0m\n\u001b[0;32m   2075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"object\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2076\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2077\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_rep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2078\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#UCI_HAR_df_act.to_csv('UCI_HAR_df_act.csv')\n",
    "#act_labels_df.to_csv('act_labels_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since merging the dataframe above took long to run, we save it and recall it\n",
    "UCI_HAR_df_proc = pd.read_csv(r'Processed_UCI_HAR.csv')\n",
    "# remove the transitional activities\n",
    "UCI_HAR_df_proc = UCI_HAR_df_proc.loc[UCI_HAR_df_proc['activity'].isin([1,2,3,4,5,6])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to split wearable sensor data into time windows, given the dataset and its frequency\n",
    "# the time window is in seconds and the overlap is a percentage\n",
    "def sliding_windows(window_length, overlap, data, frequency):\n",
    "    window = []\n",
    "    window_data = []\n",
    "    labels = []\n",
    "    sensor_readings = int(window_length * frequency)\n",
    "    diff = int(sensor_readings * (100 - overlap) / 100)\n",
    "    for i in range(0, len(data), diff):\n",
    "        x_acc = data['x-acc'].values[i:i+sensor_readings]\n",
    "        y_acc = data['y-acc'].values[i:i+sensor_readings]\n",
    "        z_acc = data['z-acc'].values[i:i+sensor_readings]\n",
    "        x_gyro = data['x-gyro'].values[i:i+sensor_readings]\n",
    "        y_gyro = data['y-gyro'].values[i:i+sensor_readings]\n",
    "        z_gyro = data['z-gyro'].values[i:i+sensor_readings]\n",
    "        window.append([x_acc,y_acc,z_acc,x_gyro,y_gyro,z_gyro])\n",
    "        window_arr = np.asarray(window)\n",
    "        # only include windows that have the desired number of sensor readings\n",
    "        if window_arr.shape[2] == sensor_readings:\n",
    "            label = data['activity'].values[i]\n",
    "            labels.append(label)\n",
    "            window_arr.reshape(sensor_readings, 6)\n",
    "            window_data.append(window_arr)\n",
    "            window = []\n",
    "        else:\n",
    "            window = []\n",
    "        \n",
    "    window_data = np.asarray(window_data)\n",
    "    labels = np.asarray(labels)\n",
    "    # reshape into a square image\n",
    "    window_data = window_data.reshape(window_data.shape[0],int(math.sqrt(sensor_readings)),int(math.sqrt(sensor_readings)),6)\n",
    "    \n",
    "    return window_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to sort the data into time windows and split these into test and training sets of the features and labels\n",
    "def train_test(window_length, overlap, data, frequency):\n",
    "    features, labels = sliding_windows(window_length, overlap, data, frequency)\n",
    "    train_features, test_features, train_labels, test_labels  = train_test_split(features, labels, test_size=0.2)\n",
    "    return train_features, test_features, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and test sets for the three datasets and for different sample generation parameters\n",
    "# overlap of 25%, 50% and 75%\n",
    "# window length of 1, 1.5, 2 and 2.5 seconds\n",
    "# 12 different sample parameter configurations\n",
    "# 12x3=36 datasets in total\n",
    "\n",
    "# USC-HAD (100Hz)\n",
    "# 1 second window size, 25% overlap\n",
    "USC_features_train_1_sec_25ol, USC_features_test_1_sec_25ol, USC_labels_train_1_sec_25ol, USC_labels_test_1_sec_25ol=\\\n",
    "train_test(1, 25, USC_HAD_df, 100)\n",
    "# 1 second window size, 50% overlap\n",
    "USC_features_train_1_sec_50ol, USC_features_test_1_sec_50ol, USC_labels_train_1_sec_50ol, USC_labels_test_1_sec_50ol =\\\n",
    "train_test(1, 50, USC_HAD_df, 100)\n",
    "# 1 second window size, 75% overlap\n",
    "USC_features_train_1_sec_75ol, USC_features_test_1_sec_75ol, USC_labels_train_1_sec_75ol, USC_labels_test_1_sec_75ol =\\\n",
    "train_test(1, 75, USC_HAD_df, 100)\n",
    "# 1.5 second window size, 25% overlap\n",
    "USC_features_train_1_5_sec_25ol, USC_features_test_1_5_sec_25ol, USC_labels_train_1_5_sec_25ol, USC_labels_test_1_5_sec_25ol\\\n",
    "= train_test(1.44, 25, USC_HAD_df, 100)\n",
    "# 1.5 second window size, 50% overlap\n",
    "USC_features_train_1_5_sec_50ol, USC_features_test_1_5_sec_50ol, USC_labels_train_1_5_sec_50ol, USC_labels_test_1_5_sec_50ol\\\n",
    "= train_test(1.44, 50, USC_HAD_df, 100)\n",
    "# 1.5 second window size, 75% overlap\n",
    "USC_features_train_1_5_sec_75ol, USC_features_test_1_5_sec_75ol, USC_labels_train_1_5_sec_75ol, USC_labels_test_1_5_sec_75ol\\\n",
    "= train_test(1.44, 75, USC_HAD_df, 100)\n",
    "# 2 second window size, 25% overlap\n",
    "USC_features_train_2_sec_25ol, USC_features_test_2_sec_25ol, USC_labels_train_2_sec_25ol, USC_labels_test_2_sec_25ol =\\\n",
    "train_test(1.96, 25, USC_HAD_df, 100)\n",
    "# 2 second window size, 50% overlap\n",
    "USC_features_train_2_sec_50ol, USC_features_test_2_sec_50ol, USC_labels_train_2_sec_50ol, USC_labels_test_2_sec_50ol =\\\n",
    "train_test(1.96, 50, USC_HAD_df, 100)\n",
    "# 2 second window size, 75% overlap\n",
    "USC_features_train_2_sec_75ol, USC_features_test_2_sec_75ol, USC_labels_train_2_sec_75ol, USC_labels_test_2_sec_75ol =\\\n",
    "train_test(1.96, 75, USC_HAD_df, 100)\n",
    "# 2.5 second window size, 25% overlap\n",
    "USC_features_train_2_5_sec_25ol, USC_features_test_2_5_sec_25ol, USC_labels_train_2_5_sec_25ol, USC_labels_test_2_5_sec_25ol\\\n",
    "= train_test(2.56, 25, USC_HAD_df, 100)\n",
    "# 2.5 second window size, 50% overlap\n",
    "USC_features_train_2_5_sec_50ol, USC_features_test_2_5_sec_50ol, USC_labels_train_2_5_sec_50ol, USC_labels_test_2_5_sec_50ol\\\n",
    "= train_test(2.56, 50, USC_HAD_df, 100)\n",
    "# 2.5 second window size, 75% overlap\n",
    "USC_features_train_2_5_sec_75ol, USC_features_test_2_5_sec_75ol, USC_labels_train_2_5_sec_75ol, USC_labels_test_2_5_sec_75ol\\\n",
    "= train_test(2.56, 75, USC_HAD_df, 100)\n",
    "\n",
    "# UTD-MHAD (50Hz)\n",
    "# 1 second window size, 25% overlap\n",
    "UTD_features_train_1_sec_25ol, UTD_features_test_1_sec_25ol, UTD_labels_train_1_sec_25ol, UTD_labels_test_1_sec_25ol =\\\n",
    "train_test(0.98, 25, UTD_MHAD_df, 50)\n",
    "# 1 second window size, 50% overlap\n",
    "UTD_features_train_1_sec_50ol, UTD_features_test_1_sec_50ol, UTD_labels_train_1_sec_50ol, UTD_labels_test_1_sec_50ol =\\\n",
    "train_test(0.98, 50, UTD_MHAD_df, 50)\n",
    "# 1 second window size, 75% overlap\n",
    "UTD_features_train_1_sec_75ol, UTD_features_test_1_sec_75ol, UTD_labels_train_1_sec_75ol, UTD_labels_test_1_sec_75ol =\\\n",
    "train_test(0.98, 75, UTD_MHAD_df, 50)\n",
    "# 1.5 second window size, 25% overlap\n",
    "UTD_features_train_1_5_sec_25ol, UTD_features_test_1_5_sec_25ol, UTD_labels_train_1_5_sec_25ol, UTD_labels_test_1_5_sec_25ol\\\n",
    "= train_test(1.62, 25, UTD_MHAD_df, 50)\n",
    "# 1.5 second window size, 50% overlap\n",
    "UTD_features_train_1_5_sec_50ol, UTD_features_test_1_5_sec_50ol, UTD_labels_train_1_5_sec_50ol, UTD_labels_test_1_5_sec_50ol\\\n",
    "= train_test(1.62, 50, UTD_MHAD_df, 50)\n",
    "# 1.5 second window size, 75% overlap\n",
    "UTD_features_train_1_5_sec_75ol, UTD_features_test_1_5_sec_75ol, UTD_labels_train_1_5_sec_75ol, UTD_labels_test_1_5_sec_75ol\\\n",
    "= train_test(1.62, 75, UTD_MHAD_df, 50)\n",
    "# 2 second window size, 25% overlap\n",
    "UTD_features_train_2_sec_25ol, UTD_features_test_2_sec_25ol, UTD_labels_train_2_sec_25ol, UTD_labels_test_2_sec_25ol =\\\n",
    "train_test(2, 25, UTD_MHAD_df, 50)\n",
    "# 2 second window size, 50% overlap\n",
    "UTD_features_train_2_sec_50ol, UTD_features_test_2_sec_50ol, UTD_labels_train_2_sec_50ol, UTD_labels_test_2_sec_50ol =\\\n",
    "train_test(2, 50, UTD_MHAD_df, 50)\n",
    "# 2 second window size, 75% overlap\n",
    "UTD_features_train_2_sec_75ol, UTD_features_test_2_sec_75ol, UTD_labels_train_2_sec_75ol, UTD_labels_test_2_sec_75ol =\\\n",
    "train_test(2, 75, UTD_MHAD_df, 50)\n",
    "# 2.5 second window size, 25% overlap\n",
    "UTD_features_train_2_5_sec_25ol, UTD_features_test_2_5_sec_25ol, UTD_labels_train_2_5_sec_25ol, UTD_labels_test_2_5_sec_25ol\\\n",
    "= train_test(2.42, 25, UTD_MHAD_df, 50)\n",
    "# 2.5 second window size, 50% overlap\n",
    "UTD_features_train_2_5_sec_50ol, UTD_features_test_2_5_sec_50ol, UTD_labels_train_2_5_sec_50ol, UTD_labels_test_2_5_sec_50ol\\\n",
    "= train_test(2.42, 50, UTD_MHAD_df, 50)\n",
    "# 2.5 second window size, 75% overlap\n",
    "UTD_features_train_2_5_sec_75ol, UTD_features_test_2_5_sec_75ol, UTD_labels_train_2_5_sec_75ol, UTD_labels_test_2_5_sec_75ol\\\n",
    "= train_test(2.42, 75, UTD_MHAD_df, 50)\n",
    "\n",
    "# UCI-HAR (50Hz)\n",
    "# 1 second window size, 25% overlap\n",
    "UCI_features_train_1_sec_25ol, UCI_features_test_1_sec_25ol, UCI_labels_train_1_sec_25ol, UCI_labels_test_1_sec_25ol =\\\n",
    "train_test(0.98, 25, UCI_HAR_df_proc, 50)\n",
    "# 1 second window size, 50% overlap\n",
    "UCI_features_train_1_sec_50ol, UCI_features_test_1_sec_50ol, UCI_labels_train_1_sec_50ol, UCI_labels_test_1_sec_50ol =\\\n",
    "train_test(0.98, 50, UCI_HAR_df_proc, 50)\n",
    "# 1 second window size, 75% overlap\n",
    "UCI_features_train_1_sec_75ol, UCI_features_test_1_sec_75ol, UCI_labels_train_1_sec_75ol, UCI_labels_test_1_sec_75ol =\\\n",
    "train_test(0.98, 75, UCI_HAR_df_proc, 50)\n",
    "# 1.5 second window size, 25% overlap\n",
    "UCI_features_train_1_5_sec_25ol, UCI_features_test_1_5_sec_25ol, UCI_labels_train_1_5_sec_25ol, UCI_labels_test_1_5_sec_25ol\\\n",
    "= train_test(1.62, 25, UCI_HAR_df_proc, 50)\n",
    "# 1.5 second window size, 50% overlap\n",
    "UCI_features_train_1_5_sec_50ol, UCI_features_test_1_5_sec_50ol, UCI_labels_train_1_5_sec_50ol, UCI_labels_test_1_5_sec_50ol\\\n",
    "= train_test(1.62, 50, UCI_HAR_df_proc, 50)\n",
    "# 1.5 second window size, 75% overlap\n",
    "UCI_features_train_1_5_sec_75ol, UCI_features_test_1_5_sec_75ol, UCI_labels_train_1_5_sec_75ol, UCI_labels_test_1_5_sec_75ol\\\n",
    "= train_test(1.62, 75, UCI_HAR_df_proc, 50)\n",
    "# 2 second window size, 25% overlap\n",
    "UCI_features_train_2_sec_25ol, UCI_features_test_2_sec_25ol, UCI_labels_train_2_sec_25ol, UCI_labels_test_2_sec_25ol =\\\n",
    "train_test(2, 25, UCI_HAR_df_proc, 50)\n",
    "# 2 second window size, 50% overlap\n",
    "UCI_features_train_2_sec_50ol, UCI_features_test_2_sec_50ol, UCI_labels_train_2_sec_50ol, UCI_labels_test_2_sec_50ol =\\\n",
    "train_test(2, 50, UCI_HAR_df_proc, 50)\n",
    "# 2 second window size, 75% overlap\n",
    "UCI_features_train_2_sec_75ol, UCI_features_test_2_sec_75ol, UCI_labels_train_2_sec_75ol, UCI_labels_test_2_sec_75ol =\\\n",
    "train_test(2, 75, UCI_HAR_df_proc, 50)\n",
    "# 2.5 second window size, 25% overlap\n",
    "UCI_features_train_2_5_sec_25ol, UCI_features_test_2_5_sec_25ol, UCI_labels_train_2_5_sec_25ol, UCI_labels_test_2_5_sec_25ol\\\n",
    "= train_test(2.42, 25, UCI_HAR_df_proc, 50)\n",
    "# 2.5 second window size, 50% overlap\n",
    "UCI_features_train_2_5_sec_50ol, UCI_features_test_2_5_sec_50ol, UCI_labels_train_2_5_sec_50ol, UCI_labels_test_2_5_sec_50ol\\\n",
    "= train_test(2.42, 50, UCI_HAR_df_proc, 50)\n",
    "# 2.5 second window size, 75% overlap\n",
    "UCI_features_train_2_5_sec_75ol, UCI_features_test_2_5_sec_75ol, UCI_labels_train_2_5_sec_75ol, UCI_labels_test_2_5_sec_75ol\\\n",
    "= train_test(2.42, 75, UCI_HAR_df_proc, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save each dataset\n",
    "# USC-HAD\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_train_1_sec_25ol.npy', USC_features_train_1_sec_25ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_test_1_sec_25ol.npy', USC_features_test_1_sec_25ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_train_1_sec_25ol.npy', USC_labels_train_1_sec_25ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_test_1_sec_25ol.npy', USC_labels_test_1_sec_25ol)\n",
    "\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_train_1_sec_50ol.npy', USC_features_train_1_sec_50ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_test_1_sec_50ol.npy', USC_features_test_1_sec_50ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_train_1_sec_50ol.npy', USC_labels_train_1_sec_50ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_test_1_sec_50ol.npy', USC_labels_test_1_sec_50ol)\n",
    "\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_train_1_sec_75ol.npy', USC_features_train_1_sec_75ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_test_1_sec_75ol.npy', USC_features_test_1_sec_75ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_train_1_sec_75ol.npy', USC_labels_train_1_sec_75ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_test_1_sec_75ol.npy', USC_labels_test_1_sec_75ol)\n",
    "\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_train_1_5_sec_25ol.npy', USC_features_train_1_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_test_1_5_sec_25ol.npy', USC_features_test_1_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_train_1_5_sec_25ol.npy', USC_labels_train_1_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_test_1_5_sec_25ol.npy', USC_labels_test_1_5_sec_25ol)\n",
    "\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_train_1_5_sec_50ol.npy', USC_features_train_1_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_test_1_5_sec_50ol.npy', USC_features_test_1_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_train_1_5_sec_50ol.npy', USC_labels_train_1_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_test_1_5_sec_50ol.npy', USC_labels_test_1_5_sec_50ol)\n",
    "\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_train_1_5_sec_75ol.npy', USC_features_train_1_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_test_1_5_sec_75ol.npy', USC_features_test_1_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_train_1_5_sec_75ol.npy', USC_labels_train_1_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_test_1_5_sec_75ol.npy', USC_labels_test_1_5_sec_75ol)\n",
    "\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_train_2_sec_25ol.npy', USC_features_train_2_sec_25ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_test_2_sec_25ol.npy', USC_features_test_2_sec_25ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_train_2_sec_25ol.npy', USC_labels_train_2_sec_25ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_test_2_sec_25ol.npy', USC_labels_test_2_sec_25ol)\n",
    "\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_train_2_sec_50ol.npy', USC_features_train_2_sec_50ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_test_2_sec_50ol.npy', USC_features_test_2_sec_50ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_train_2_sec_50ol.npy', USC_labels_train_2_sec_50ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_test_2_sec_50ol.npy', USC_labels_test_2_sec_50ol)\n",
    "\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_train_2_sec_75ol.npy', USC_features_train_2_sec_75ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_test_2_sec_75ol.npy', USC_features_test_2_sec_75ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_train_2_sec_75ol.npy', USC_labels_train_2_sec_75ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_test_2_sec_75ol.npy', USC_labels_test_2_sec_75ol)\n",
    "\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_train_2_5_sec_25ol.npy', USC_features_train_2_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_test_2_5_sec_25ol.npy', USC_features_test_2_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_train_2_5_sec_25ol.npy', USC_labels_train_2_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_test_2_5_sec_25ol.npy', USC_labels_test_2_5_sec_25ol)\n",
    "\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_train_2_5_sec_50ol.npy', USC_features_train_2_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_test_2_5_sec_50ol.npy', USC_features_test_2_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_train_2_5_sec_50ol.npy', USC_labels_train_2_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_test_2_5_sec_50ol.npy', USC_labels_test_2_5_sec_50ol)\n",
    "\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_train_2_5_sec_75ol.npy', USC_features_train_2_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_features_test_2_5_sec_75ol.npy', USC_features_test_2_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_train_2_5_sec_75ol.npy', USC_labels_train_2_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/USC-HAD/USC_labels_test_2_5_sec_75ol.npy', USC_labels_test_2_5_sec_75ol)\n",
    "\n",
    "# UTD-MHAD\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_train_1_sec_25ol.npy', UTD_features_train_1_sec_25ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_test_1_sec_25ol.npy', UTD_features_test_1_sec_25ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_train_1_sec_25ol.npy', UTD_labels_train_1_sec_25ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_test_1_sec_25ol.npy', UTD_labels_test_1_sec_25ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_train_1_sec_50ol.npy', UTD_features_train_1_sec_50ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_test_1_sec_50ol.npy', UTD_features_test_1_sec_50ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_train_1_sec_50ol.npy', UTD_labels_train_1_sec_50ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_test_1_sec_50ol.npy', UTD_labels_test_1_sec_50ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_train_1_sec_75ol.npy', UTD_features_train_1_sec_75ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_test_1_sec_75ol.npy', UTD_features_test_1_sec_75ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_train_1_sec_75ol.npy', UTD_labels_train_1_sec_75ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_test_1_sec_75ol.npy', UTD_labels_test_1_sec_75ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_train_1_5_sec_25ol.npy', UTD_features_train_1_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_test_1_5_sec_25ol.npy', UTD_features_test_1_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_train_1_5_sec_25ol.npy', UTD_labels_train_1_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_test_1_5_sec_25ol.npy', UTD_labels_test_1_5_sec_25ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_train_1_5_sec_50ol.npy', UTD_features_train_1_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_test_1_5_sec_50ol.npy', UTD_features_test_1_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_train_1_5_sec_50ol.npy', UTD_labels_train_1_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_test_1_5_sec_50ol.npy', UTD_labels_test_1_5_sec_50ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_train_1_5_sec_75ol.npy', UTD_features_train_1_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_test_1_5_sec_75ol.npy', UTD_features_test_1_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_train_1_5_sec_75ol.npy', UTD_labels_train_1_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_test_1_5_sec_75ol.npy', UTD_labels_test_1_5_sec_75ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_train_2_sec_25ol.npy', UTD_features_train_2_sec_25ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_test_2_sec_25ol.npy', UTD_features_test_2_sec_25ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_train_2_sec_25ol.npy', UTD_labels_train_2_sec_25ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_test_2_sec_25ol.npy', UTD_labels_test_2_sec_25ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_train_2_sec_50ol.npy', UTD_features_train_2_sec_50ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_test_2_sec_50ol.npy', UTD_features_test_2_sec_50ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_train_2_sec_50ol.npy', UTD_labels_train_2_sec_50ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_test_2_sec_50ol.npy', UTD_labels_test_2_sec_50ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_train_2_sec_75ol.npy', UTD_features_train_2_sec_75ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_test_2_sec_75ol.npy', UTD_features_test_2_sec_75ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_train_2_sec_75ol.npy', UTD_labels_train_2_sec_75ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_test_2_sec_75ol.npy', UTD_labels_test_2_sec_75ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_train_2_5_sec_25ol.npy', UTD_features_train_2_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_test_2_5_sec_25ol.npy', UTD_features_test_2_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_train_2_5_sec_25ol.npy', UTD_labels_train_2_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_test_2_5_sec_25ol.npy', UTD_labels_test_2_5_sec_25ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_train_2_5_sec_50ol.npy', UTD_features_train_2_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_test_2_5_sec_50ol.npy', UTD_features_test_2_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_train_2_5_sec_50ol.npy', UTD_labels_train_2_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_test_2_5_sec_50ol.npy', UTD_labels_test_2_5_sec_50ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_train_2_5_sec_75ol.npy', UTD_features_train_2_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_features_test_2_5_sec_75ol.npy', UTD_features_test_2_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_train_2_5_sec_75ol.npy', UTD_labels_train_2_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/UTD-MHAD/UTD_labels_test_2_5_sec_75ol.npy', UTD_labels_test_2_5_sec_75ol)\n",
    "\n",
    "# UCI-HAR\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_train_1_sec_25ol.npy', UCI_features_train_1_sec_25ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_test_1_sec_25ol.npy', UCI_features_test_1_sec_25ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_train_1_sec_25ol.npy', UCI_labels_train_1_sec_25ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_test_1_sec_25ol.npy', UCI_labels_test_1_sec_25ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_train_1_sec_50ol.npy', UCI_features_train_1_sec_50ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_test_1_sec_50ol.npy', UCI_features_test_1_sec_50ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_train_1_sec_50ol.npy', UCI_labels_train_1_sec_50ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_test_1_sec_50ol.npy', UCI_labels_test_1_sec_50ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_train_1_sec_75ol.npy', UCI_features_train_1_sec_75ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_test_1_sec_75ol.npy', UCI_features_test_1_sec_75ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_train_1_sec_75ol.npy', UCI_labels_train_1_sec_75ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_test_1_sec_75ol.npy', UCI_labels_test_1_sec_75ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_train_1_5_sec_25ol.npy', UCI_features_train_1_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_test_1_5_sec_25ol.npy', UCI_features_test_1_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_train_1_5_sec_25ol.npy', UCI_labels_train_1_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_test_1_5_sec_25ol.npy', UCI_labels_test_1_5_sec_25ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_train_1_5_sec_50ol.npy', UCI_features_train_1_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_test_1_5_sec_50ol.npy', UCI_features_test_1_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_train_1_5_sec_50ol.npy', UCI_labels_train_1_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_test_1_5_sec_50ol.npy', UCI_labels_test_1_5_sec_50ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_train_1_5_sec_75ol.npy', UCI_features_train_1_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_test_1_5_sec_75ol.npy', UCI_features_test_1_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_train_1_5_sec_75ol.npy', UCI_labels_train_1_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_test_1_5_sec_75ol.npy', UCI_labels_test_1_5_sec_75ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_train_2_sec_25ol.npy', UCI_features_train_2_sec_25ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_test_2_sec_25ol.npy', UCI_features_test_2_sec_25ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_train_2_sec_25ol.npy', UCI_labels_train_2_sec_25ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_test_2_sec_25ol.npy', UCI_labels_test_2_sec_25ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_train_2_sec_50ol.npy', UCI_features_train_2_sec_50ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_test_2_sec_50ol.npy', UCI_features_test_2_sec_50ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_train_2_sec_50ol.npy', UCI_labels_train_2_sec_50ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_test_2_sec_50ol.npy', UCI_labels_test_2_sec_50ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_train_2_sec_75ol.npy', UCI_features_train_2_sec_75ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_test_2_sec_75ol.npy', UCI_features_test_2_sec_75ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_train_2_sec_75ol.npy', UCI_labels_train_2_sec_75ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_test_2_sec_75ol.npy', UCI_labels_test_2_sec_75ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_train_2_5_sec_25ol.npy', UCI_features_train_2_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_test_2_5_sec_25ol.npy', UCI_features_test_2_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_train_2_5_sec_25ol.npy', UCI_labels_train_2_5_sec_25ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_test_2_5_sec_25ol.npy', UCI_labels_test_2_5_sec_25ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_train_2_5_sec_50ol.npy', UCI_features_train_2_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_test_2_5_sec_50ol.npy', UCI_features_test_2_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_train_2_5_sec_50ol.npy', UCI_labels_train_2_5_sec_50ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_test_2_5_sec_50ol.npy', UCI_labels_test_2_5_sec_50ol)\n",
    "\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_train_2_5_sec_75ol.npy', UCI_features_train_2_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_features_test_2_5_sec_75ol.npy', UCI_features_test_2_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_train_2_5_sec_75ol.npy', UCI_labels_train_2_5_sec_75ol)\n",
    "np.save(f'Data/Window Data/UCI-HAR/UCI_labels_test_2_5_sec_75ol.npy', UCI_labels_test_2_5_sec_75ol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
